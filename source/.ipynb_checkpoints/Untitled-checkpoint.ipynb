{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f2aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commentare il codice\n",
    "# patience nella discesa del gradiente, early stopping\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "# salvare i pesi del modello scelto\n",
    "# pre-embedding\n",
    "# cuda cpu..\n",
    "# evaluate the result\n",
    "# controllo per input errati, fuori da un range\n",
    "# differenza tra numero di token e numero di words\n",
    "# rimuovere punteggiatura?\n",
    "# your model must be loaded on the device \"device\"\n",
    "# model.py copiato nella cartella stud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e35bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import stud.MakeDataset as md\n",
    "import stud.POSTaggerModel as pt\n",
    "import stud.Trainer as tr\n",
    "import importlib\n",
    "importlib.reload(md)\n",
    "importlib.reload(pt)\n",
    "importlib.reload(tr)\n",
    "\n",
    "import stud.SkipGram as sk\n",
    "import stud.Word2VecDataset as wv\n",
    "import stud.SKTrainer as sktr\n",
    "importlib.reload(sk)\n",
    "importlib.reload(sktr)\n",
    "importlib.reload(wv)\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e1a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8866f07",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m stud\u001b[38;5;241m.\u001b[39mimplementation\u001b[38;5;241m.\u001b[39mbuild_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 18\u001b[0m \u001b[43mstud\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimplementation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStudentModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "import stud.implementation \n",
    "import importlib\n",
    "importlib.reload(stud.implementation)\n",
    "data_params = {}\n",
    "stop_token = '#'\n",
    "unk_token = 'UNK'\n",
    "pad_token = '<pad>'\n",
    "data_params['window_size'] = 5\n",
    "data_params['window_shift'] = 1\n",
    "data_params['stop_token'] = stop_token\n",
    "data_params['unk_token'] = unk_token\n",
    "data_params['pad_token'] = pad_token\n",
    "data_params['vocab_size'] = 10000\n",
    "\n",
    "#stud.implementation.StudentModel.build_model(data_params)\n",
    "stud.implementation.build_model('gpu')\n",
    "tokens = [['hi']]\n",
    "stud.implementation.StudentModel.predict(tokens = tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025463e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc346ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8468273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efc2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c6df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train.tsv'\n",
    "dev_path = '../data/dev.tsv'\n",
    "output_folder = '../model/Output folder'\n",
    "stop_token = '#'\n",
    "unk_token = 'UNK'\n",
    "pad_token = '<pad>'\n",
    "window_size = 5\n",
    "window_shift = 1\n",
    "vocab_size = 10000\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b254a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no\n",
    "data = md.MakeDataset(train_path, window_size, window_shift, stop_token, unk_token, pad_token, vocab_size)\n",
    "with open(f'stud/data.pickle', 'wb') as file:\n",
    "    pickle.dump(data, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf05c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'stud/data.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "train_dataset = data.make_dataset(train_path)\n",
    "train_dataset = DataLoader(train_dataset, batch_size = 5000, shuffle = True)\n",
    "dev_dataset = data.make_dataset(dev_path)\n",
    "dev_dataset = DataLoader(dev_dataset, batch_size = 1000, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcf5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(wv)\n",
    "word2vec = wv.Word2VecDataset(data.tok_sentences, data.word2id, window_size, data.frequency, data.tot_occurrences)\n",
    "word2vec = DataLoader(word2vec,batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5b418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                         | 1/20 [00:34<11:00, 34.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, avg epoch loss = 7.1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 2/20 [01:09<10:24, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, avg epoch loss = 6.3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 2/20 [01:38<14:45, 49.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m sk_model \u001b[38;5;241m=\u001b[39m sk\u001b[38;5;241m.\u001b[39mSkipGram(vocab_size, embedding_dim, data\u001b[38;5;241m.\u001b[39mid2word)\n\u001b[1;32m      5\u001b[0m sk_trainer \u001b[38;5;241m=\u001b[39m sktr\u001b[38;5;241m.\u001b[39mSKTrainer(sk_model, optim\u001b[38;5;241m.\u001b[39mAdam(sk_model\u001b[38;5;241m.\u001b[39mparameters()))\n\u001b[0;32m----> 6\u001b[0m \u001b[43msk_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword2vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstud/emb_model.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      9\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(sk_model, file)\n",
      "File \u001b[0;32m~/Desktop/Università - corsi e materiale/NLP/HW1/torchia_1679164_hw1/hw1/stud/SKTrainer.py:25\u001b[0m, in \u001b[0;36mSKTrainer.train\u001b[0;34m(self, train_dataset, output_folder, vocab_size, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inputs):\n\u001b[1;32m     23\u001b[0m     one_hot_input[i, x] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 25\u001b[0m output_distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_hot_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss_function(output_distribution, targets) \n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.python-environments/default/lib64/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Università - corsi e materiale/NLP/HW1/torchia_1679164_hw1/hw1/stud/SkipGram.py:15\u001b[0m, in \u001b[0;36mSkipGram.forward\u001b[0;34m(self, input_idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_idx):\n\u001b[0;32m---> 15\u001b[0m     input_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_idx\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     16\u001b[0m     output_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_weights(input_embeddings)\n\u001b[1;32m     17\u001b[0m     output \u001b[38;5;241m=\u001b[39m output_embeddings\n",
      "File \u001b[0;32m~/.python-environments/default/lib64/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.python-environments/default/lib64/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# no\n",
    "importlib.reload(sk)\n",
    "importlib.reload(sktr)\n",
    "sk_model = sk.SkipGram(vocab_size, embedding_dim, data.id2word)\n",
    "sk_trainer = sktr.SKTrainer(sk_model, optim.Adam(sk_model.parameters()))\n",
    "sk_trainer.train(word2vec, output_folder, vocab_size, 20)\n",
    "\n",
    "with open(f'stud/emb_model.pickle', 'wb') as file:\n",
    "    pickle.dump(sk_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbbe515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f'stud/emb_model.pickle', 'rb') as file:\n",
    "    sk_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3528dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = sk_model.state_dict()['output_weights.weight']\n",
    "\n",
    "class HParams():\n",
    "    vocab_size = vocab_size\n",
    "    hidden_dim = 20\n",
    "    embedding_dim = embedding_dim\n",
    "    num_classes = 13\n",
    "    bidirectional = False\n",
    "    num_layers = 1\n",
    "    dropout = 0.0\n",
    "    embeddings = weights\n",
    "    \n",
    "params = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1038901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embeddings from pretrained\n"
     ]
    }
   ],
   "source": [
    "# no\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index = data.label2id[pad_token])\n",
    "postagger = pt.POSTaggerModel(params)\n",
    "trainer = tr.Trainer(\n",
    "    model = postagger,\n",
    "    loss_function = loss_function,\n",
    "    optimizer = optim.Adam(postagger.parameters()),\n",
    "    label_vocab = data.label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e13f470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 30/30 [36:41<00:00, 73.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# no\n",
    "early_stopping = False\n",
    "early_stopping_patience = 2\n",
    "epochs = 30\n",
    "\n",
    "history = trainer.train(\n",
    "    train_dataset,\n",
    "    dev_dataset,\n",
    "    output_folder,\n",
    "    epochs,\n",
    "    early_stopping,\n",
    "    early_stopping_patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97eb133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no\n",
    "with open(f'stud/model.pickle', 'wb') as file:\n",
    "    pickle.dump(postagger, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5ec9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'stud/model.pickle', 'rb') as file:\n",
    "    postagger = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6baca897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2818547854056725, 0.918552829669072, 0.8666811264478244, 0.8169649793551519, 0.764442095389733, 0.7303814062705407, 0.7134072551360497, 0.7022312100117023, 0.6934135602070735, 0.6841432268802936, 0.6740672450799209, 0.6651996099031888, 0.6568704705971938, 0.6490186361166147, 0.6396339444013742, 0.6311164452479436, 0.6235317404453571, 0.6170247334700364, 0.61058221413539, 0.6049903677060053, 0.6006358907772944, 0.5965834397536057, 0.5939334493417007, 0.5920750957268935, 0.5886372098555932, 0.5856907459405752, 0.5845159979966971, 0.5828625834905184, 0.5819958540109488, 0.580972854907696]\n"
     ]
    }
   ],
   "source": [
    "print(history['valid_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "456b8ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['valid_history'])\n",
    "plt.scatter(range(len(history['valid_history'])),history['valid_history'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe541fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.580972854907696\n"
     ]
    }
   ],
   "source": [
    "epoch = epochs - 1\n",
    "#postagger.load_state_dict(torch.load(os.path.join(output_folder,'state.pt')))\n",
    "postagger.eval()\n",
    "\n",
    "valid_loss = 0.0 \n",
    "with torch.no_grad():\n",
    "    for sample in dev_dataset:\n",
    "        inputs = sample['inputs']\n",
    "        labels = sample['outputs'].view(-1)\n",
    "        predictions = postagger(inputs)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        sample_loss = loss_function(predictions, labels)\n",
    "        valid_loss += sample_loss.tolist()\n",
    "print(valid_loss/len(dev_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d9456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb15bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444149c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
